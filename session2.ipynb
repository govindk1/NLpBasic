{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len((stopwords.words('English'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('german')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CMU WORDLIST</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133737\n"
     ]
    }
   ],
   "source": [
    "data = nltk.corpus.cmudict.entries()\n",
    "#length is too large that's why not printing it\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abts', ['EY1', 'B', 'IY1', 'T', 'IY1', 'EH1', 'S']),\n",
       " ('abu', ['AE1', 'B', 'UW0']),\n",
       " ('abudrahm', ['AH0', 'B', 'AH1', 'D', 'R', 'AH0', 'M']),\n",
       " ('abuellah', ['AH0', 'B', 'W', 'EH1', 'L', 'AH0']),\n",
       " (\"abuellah's\", ['AH0', 'B', 'W', 'EH1', 'L', 'AH0', 'Z']),\n",
       " ('abuladze', ['AE2', 'B', 'Y', 'UW0', 'L', 'AE1', 'D', 'Z', 'IY0']),\n",
       " ('abundance', ['AH0', 'B', 'AH1', 'N', 'D', 'AH0', 'N', 'S']),\n",
       " ('abundant', ['AH0', 'B', 'AH1', 'N', 'D', 'AH0', 'N', 'T']),\n",
       " ('abundantly', ['AH0', 'B', 'AH1', 'N', 'D', 'AH0', 'N', 'T', 'L', 'IY0']),\n",
       " ('aburto', ['AH0', 'B', 'UH1', 'R', 'T', 'OW2']),\n",
       " (\"aburto's\", ['AH0', 'B', 'UH1', 'R', 'T', 'OW2', 'Z']),\n",
       " ('abuse', ['AH0', 'B', 'Y', 'UW1', 'S']),\n",
       " ('abuse', ['AH0', 'B', 'Y', 'UW1', 'Z']),\n",
       " ('abused', ['AH0', 'B', 'Y', 'UW1', 'Z', 'D']),\n",
       " ('abuser', ['AH0', 'B', 'Y', 'UW1', 'Z', 'ER0']),\n",
       " ('abusers', ['AH0', 'B', 'Y', 'UW1', 'Z', 'ER0', 'Z']),\n",
       " ('abuses', ['AH0', 'B', 'Y', 'UW1', 'S', 'IH0', 'Z']),\n",
       " ('abuses', ['AH0', 'B', 'Y', 'UW1', 'Z', 'IH0', 'Z']),\n",
       " ('abusing', ['AH0', 'B', 'Y', 'UW1', 'Z', 'IH0', 'NG']),\n",
       " ('abusive', ['AH0', 'B', 'Y', 'UW1', 'S', 'IH0', 'V']),\n",
       " ('abut', ['AH0', 'B', 'AH1', 'T']),\n",
       " ('abuts', ['AH0', 'B', 'AH1', 'T', 'S']),\n",
       " ('abutted', ['AH0', 'B', 'AH1', 'T', 'AH0', 'D']),\n",
       " ('abutting', ['AH0', 'B', 'AH1', 'T', 'IH0', 'NG']),\n",
       " ('abuzz', ['AH0', 'B', 'AH1', 'Z']),\n",
       " ('abysmal', ['AH0', 'B', 'IH1', 'Z', 'M', 'AH0', 'L']),\n",
       " ('abysmally', ['AH0', 'B', 'IH1', 'Z', 'M', 'AH0', 'L', 'IY0']),\n",
       " ('abyss', ['AH0', 'B', 'IH1', 'S']),\n",
       " ('abyssinia', ['AE0', 'B', 'S', 'IH1', 'N', 'IY2', 'AH0']),\n",
       " ('abyssinian', ['AE0', 'B', 'S', 'IH1', 'N', 'IY2', 'AH0', 'N']),\n",
       " ('abzug', ['AE1', 'B', 'Z', 'AH2', 'G']),\n",
       " ('abzug', ['AE1', 'B', 'Z', 'UH2', 'G']),\n",
       " ('ac', ['EY1', 'S', 'IY1']),\n",
       " ('aca', ['AE1', 'K', 'AH0']),\n",
       " ('acacia', ['AH0', 'K', 'EY1', 'SH', 'AH0']),\n",
       " ('academe', ['AE1', 'K', 'AH0', 'D', 'IY2', 'M']),\n",
       " ('academia', ['AE2', 'K', 'AH0', 'D', 'IY1', 'M', 'IY0', 'AH0']),\n",
       " ('academic', ['AE2', 'K', 'AH0', 'D', 'EH1', 'M', 'IH0', 'K']),\n",
       " ('academically',\n",
       "  ['AE2', 'K', 'AH0', 'D', 'EH1', 'M', 'IH0', 'K', 'L', 'IY0']),\n",
       " ('academician',\n",
       "  ['AE2', 'K', 'AH0', 'D', 'AH0', 'M', 'IH1', 'SH', 'AH0', 'N']),\n",
       " ('academicians',\n",
       "  ['AE2', 'K', 'AH0', 'D', 'AH0', 'M', 'IH1', 'SH', 'AH0', 'N', 'Z']),\n",
       " ('academicians',\n",
       "  ['AH0', 'K', 'AE2', 'D', 'AH0', 'M', 'IH1', 'SH', 'AH0', 'N', 'Z']),\n",
       " ('academics', ['AE2', 'K', 'AH0', 'D', 'EH1', 'M', 'IH0', 'K', 'S']),\n",
       " ('academies', ['AH0', 'K', 'AE1', 'D', 'AH0', 'M', 'IY0', 'Z']),\n",
       " ('academy', ['AH0', 'K', 'AE1', 'D', 'AH0', 'M', 'IY0']),\n",
       " (\"academy's\", ['AH0', 'K', 'AE1', 'D', 'AH0', 'M', 'IY0', 'Z']),\n",
       " ('acadia', ['AH0', 'K', 'EY1', 'D', 'IY0', 'AH0']),\n",
       " ('acampo', ['AH0', 'K', 'AA1', 'M', 'P', 'OW0']),\n",
       " ('acampora', ['AH0', 'K', 'AE1', 'M', 'P', 'ER0', 'AH0']),\n",
       " ('acantha', ['AA0', 'K', 'AA1', 'N', 'DH', 'AH0'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[400:450]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>WORDNET</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('good.n.01'),\n",
       " Synset('good.n.02'),\n",
       " Synset('good.n.03'),\n",
       " Synset('commodity.n.01'),\n",
       " Synset('good.a.01'),\n",
       " Synset('full.s.06'),\n",
       " Synset('good.a.03'),\n",
       " Synset('estimable.s.02'),\n",
       " Synset('beneficial.s.01'),\n",
       " Synset('good.s.06'),\n",
       " Synset('good.s.07'),\n",
       " Synset('adept.s.01'),\n",
       " Synset('good.s.09'),\n",
       " Synset('dear.s.02'),\n",
       " Synset('dependable.s.04'),\n",
       " Synset('good.s.12'),\n",
       " Synset('good.s.13'),\n",
       " Synset('effective.s.04'),\n",
       " Synset('good.s.15'),\n",
       " Synset('good.s.16'),\n",
       " Synset('good.s.17'),\n",
       " Synset('good.s.18'),\n",
       " Synset('good.s.19'),\n",
       " Synset('good.s.20'),\n",
       " Synset('good.s.21'),\n",
       " Synset('well.r.01'),\n",
       " Synset('thoroughly.r.02')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effective', 'good', 'in_effect', 'in_force']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('effective.s.04').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancstr = LancasterStemmer()\n",
    "lancstr.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mang'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('french')\n",
    "snowball.stem('manges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A quick brown fox jumps over a lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quick brown fox jump over a lazi dog\n"
     ]
    }
   ],
   "source": [
    "example1 = [porter.stem(token) for token in text.split(\" \")]\n",
    "print(\" \".join(example1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('radii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('better', pos = 'a' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
